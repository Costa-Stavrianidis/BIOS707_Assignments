---
title: "Costa Stavrianidis Homework 3"
output: html_document
---

---

*In this homework, the objectives are to*

1. Use R to examine and preprocess a dataset

2. Implement Unsupervised learning methods in a real-world scenario, including: Principal Component Analysis, Hierarchical Clustering, and K-means Clustering in R

3. Visualize and understand how to employ Principal Components, Hierarchical Clustering Dendrograms, and K-means Clustering in R

Please make sure to **print your knitted .html file into a pdf before you submit it to the Gradescope, and you may only submit your .rmd file to Sakai**.(Since Gradescope only allow you to upload pdf file, while sometimes students have problems in knitting pdf directly, hence please knit your rmd files as a html and print the html file as pdf.)  **5 points will be deducted for every assignment submission that does not include either the RMarkdown file or the knitted html file.** Your code should be adequately commented to clearly explain the steps you used to produce the analyses. RMarkdown homework files should be uploaded to Sakai with the naming convention date_lastname_firstname_HW[X].Rmd. For example, my first homework assignment would be named 20220830_Dunn_Jessilyn_HW1.Rmd. **It is important to note that 5 points will be deducted for every assignment that is named improperly.** Please add your answer to each question directly after the question prompt in  the homework .Rmd file template provided below.

```{r message=FALSE}
library(tidyverse)
library(ggplot2)
library(lubridate)
library(patchwork)
library(gridExtra)
library(psych)
library(corrplot)
library(ggfortify)
library(factoextra)
```

## Dataset
Breast Cancer Prediction from Cytopathology Data
https://www.kaggle.com/code/gpreda/breast-cancer-prediction-from-cytopathology-data/data


## Data Preparation (30 points)
1. Download the cancer data titled "Breast_Cytopatholgy.csv" from Sakai and import it into R. Look at the first 5 lines of the data to learn about the dataset. The “diagnosis” field shows whether the patient was diagnosed with a benign or malignant tumor. Please read additional information about each column online with the link above. 

```{r}
cancer <- read_csv("Breast_Cytopatholgy.csv")
head(cancer, n=5)
```

2. Answer the following questions by using the summary function or other methods of your choice:

a. How many observations are there in total?
```{r}
nrow(cancer)
```
There are 569.

b. How many independent variables are there?
```{r}
ncol(cancer) - 2
```
There are 30, because in the context of the problem, we are considering the "Diagnosis" variable to be dependent.

c. Is there any column with missing values? If yes, how many values are missing?
```{r}
colSums(is.na(cancer))
```
Yes, there are 6 missing values in the 'fractal_dimension_mean' column.

d. How many observations are there with a malignant diagnosis and how many are there with a benign diagnosis?
```{r}
sum(cancer$diagnosis == "M")
sum(cancer$diagnosis == "B")
```
212 malignant, 357 benign. 

**For this question, please type your answers in full sentences outside of R chunks. Do not just show the output of running your code.**


3. Change the "id" column into the index column (i.e. turn the ID values into row names) and delete the "id" column. Use str() to display the resulting dataframe. (5 points)
```{r, warnings=FALSE}
rownames(cancer) <- cancer$id
cancer <- cancer %>% subset(select=-id)
```


4. In this dataset, there isn't any column with a very large number of missing values. For the column(s) with some missing values, let’s impute these missing values by mean substitution. Keep in mind that if it is reasonable to assume that the observations with missing values could have different distributions and characteristics for the two different diagnosis groups, imputation must be performed separately for the two different diagnosis groups.
```{r}
# Calculate means for different outcome groups
mean_m <- cancer %>% filter(diagnosis == "M" & !is.na(fractal_dimension_mean)) %>%
  pull(fractal_dimension_mean) %>% 
  mean
mean_b <- cancer %>% filter(diagnosis == "B" & !is.na(fractal_dimension_mean)) %>%
  pull(fractal_dimension_mean) %>% 
  mean

# Set empty values in variable to mean
cancer <- cancer %>% 
  mutate(fractal_dimension_mean = ifelse(diagnosis == "M" & is.na(fractal_dimension_mean),
                                     mean_m, fractal_dimension_mean)) %>% 
  mutate(fractal_dimension_mean = ifelse(diagnosis == "B" & is.na(fractal_dimension_mean),
                                     mean_b, fractal_dimension_mean))

sum(is.na(cancer$fractal_dimension_mean))
```


5. After imputation, use "ggplot" and "facet_wrap" to plot a 10 x 3 grid of histograms to explore the data shape and distribution of all the independent variables in this dataset. The dataset has 10 sets of independent variables, and each set consists of the mean, standard error and worst value of a particular cell measurement. For example, "area_se" is the standard error of area measurements from a particular patient in this study. Remember to select a reasonable number of bins when plotting and add legends and labels when appropriate. Adjust the size of the plot display so that you can see all the facets clearly when you knit. 
```{r, fig.height=20, fig.width=10}
cancer_plot <- cancer %>% subset(select=-diagnosis) %>% gather()
plot1 <- ggplot(cancer_plot, aes(value)) + geom_histogram(bins = 10) +
  facet_wrap(~key, scales = 'free_x', ncol = 3)
plot1
```


6. If you observe the independent variable distributions closely, groups of variables that start with "area", "compactness" and "concavity" are consistently strongly skewed to the right. Apply log transform using formula $log(x+1)$ to these 9 variables. 
```{r}
# Create function for log transformation
scale1 <- function(x) (log(x+1))

# Apply function to 9 variables
cancer <- cancer %>% mutate_at(c("area_mean", "compactness_mean", "concavity_mean",
                                 "area_se", "compactness_se", "concavity_se",
                                 "area_worst", "compactness_worst", "concavity_worst"),
                               scale1)
```


7. The pre-processed dataset needs to be scaled before performing PCA. Can you give a brief explanation as to why that is the case? Standardize the dataset. Use summary() again to show that your dataset has been properly standardized by checking the means and range of values of the variables.
```{r}
# Create function for standardization
scale2 <- function(x) ((x - mean(x)) / sd(x))

# Apply function to every independent variable
cancer <- cancer %>% mutate_at(vars(-("diagnosis")), scale2)
summary(cancer)
```
PCA is looking for the sequence of linear combinations of the variables that have maximal variance. Since it is trying to maximize variance, the variables will have different variances depending on their individual scales. If you change one variable's scale from kg to g, it will then have more variance. Since the scale clearly matters for PCA, we must standardize the different variables to put them on the same scale beforehand.

## PCA (25 points)

8. Calculate the principal components using the function princomp() and print the summary of the results.
```{r}
pca_cancer <- princomp(cancer[,-1])
pca_sum <- summary(pca_cancer)
pca_sum
```


9.  Plot a scree plot using the screeplot() function.
```{r}
screeplot(pca_sum, type = 'lines')
```


10. Plot the following two plots and use patchwork/gridExtra to position the two plots side by side:
a. proportion of variance explained by the number of principal components
b. cumulative proportion of variance explained  by the number of principal components; draw horizontal lines at 88% of variance and 95% variance.

Note: please remember to clearly label your plots with titles, axis labels and legends when appropriate.
```{r, fig.width=10}
# Calculate proportion of variance for each component
pov <- pca_sum$sdev^2/sum(pca_sum$sdev^2)

# Calculate cumulative proportion of variance for each component
pov_cum <- cumsum(pov)

# Plot barplots of proportions for each component
par(mfrow=c(1,2))
barplot(pov, ylab = "Proportion of Variance Explained", 
        main = "Proportion of Variance Explained by Each \nComponent", las = 2)
barplot(pov_cum, ylab = "Cumulative Proportion of Variance Explained", 
        main = "Cumulative Proportion of Variance Explained by \nEach Component", las = 2)
```


11. What proportions of variance are captured from the first, second and third principal components? How many principal components do you need to describe at least 88% and 95% of the variance, respectively?
```{r}
print(c(pov[1], pov[2], pov[3]))
pov_cum[pov_cum>.88]
pov_cum[pov_cum>.95]
```
The first, second, and third components capture 0.44852454, 0.19109881, and 0.09291716 of the variance, respectively. 

You need 6 principal components to describe at least 88% of the variance, and 10 to capture at least 95% of the variance.

12. Which are the top 2 variables that contribute the most to the variance captured from PC1, PC2, and PC3 respectively? (hint: look at the loadings information)
```{r}
sort(abs(pca_sum$loadings[,1]), decreasing = T)[1:2]
sort(abs(pca_sum$loadings[,2]), decreasing = T)[1:2]
sort(abs(pca_sum$loadings[,3]), decreasing = T)[1:2]
```
The top 2 variables for PC1 are concave points_mean and concavity_mean. The top 2 variables for PC2 are fractal_dimension_mean and fractal_dimension_se. The top 2 variables for PC3 are texture_se and smoothness_se.

13. Plot a biplot using the biplot() function.
```{r, fig.height=10, fig.width=10}
biplot(pca_cancer)
```


14. Plot a 3 x 1 grid of scatter plots, where each plot is a scatter plot between two of the first 3 principal components, with different colors for each diagnosis group. For example, in grid cell (1,1), you should plot a scatter plot where the x-axis is PC1 and the y-axis is PC2, where red observations correspond to malignant diagnosis and blue observations correspond to the benign diagnosis. Remember to adjust the plot display size so that you can see clearly. Add legends and labels when appropriate. 
```{r, fig.height=10, fig.width=8}
# Create dataframe of principle components with their scores and diagnosis for each 
# observation
pc_3 <- pca_cancer$scores[,1:3]
pc_3_diag <- data.frame(pc_3, as.factor(cancer$diagnosis))
colnames(pc_3_diag) <- c("PC1", "PC2", "PC3", "Diagnosis")

# Plot scatterplots
plot1 <- ggplot(pc_3_diag, aes(x = PC1, y = PC2, color = Diagnosis)) + geom_point() +
  scale_color_manual(values=c("blue", "red"))
plot2 <- ggplot(pc_3_diag, aes(x = PC1, y = PC3, color = Diagnosis)) + geom_point() +
  scale_color_manual(values=c("blue", "red"))
plot3 <- ggplot(pc_3_diag, aes(x = PC2, y = PC3, color = Diagnosis)) + geom_point() +
  scale_color_manual(values=c("blue", "red"))
plotlist <- list(plot1, plot2, plot3)

grid.arrange(grobs = plotlist, ncol = 1, 
             top = "Scatterplots Between First Three Principal Components by Diagnosis")
```


## Hierarchical Clustering (15 points)

15. Calculate a dissimilarity matrix using Euclidean distance. Compute hierarchical clustering using the complete linkage method and plot the dendrogram. Use the rect.hclust() function to display dividing the dendrogram into 4 branches. 
```{r, fig.width=10, fig.height=8}
# Dissimilarity matrix
dis <- dist(cancer[,-1])

set.seed(20)
# Hierarchical clustering with complete linkage
hc <- hclust(dis, method = 'complete')

# Plotting
plot(hc)
rect.hclust(hc, 4)
```


16. Divide the dendrogram into 4 clusters using cutree() function. Then use the table() function and the diagnosis label to compare the diagnostic composition (benign vs. malignant) of each of the 4 clusters. If you had to choose diagnostic labels for each of the clusters, how would you label each(e.g. cluster 1 is benign or malignant, cluster 2 is …, etc.)?
```{r}
# Divide into 4 clusters
hc_4 <- cutree(hc, 4)

# Create dataframe with clusters and diagnosis for each observation
diagnosis <- cancer %>% pull(diagnosis)
comp <- data.frame(hc_4, diagnosis)

# Create table of amount of each diagnosis for each cluster
with(comp, table(hc_4, diagnosis))
```
Clusters 1, 2, and 4 I would label as malignant, and Cluster 3 as benign.

17. Now try 5 clusters with and plot dendrograms for hierarchical clustering using Ward’s linkage. Then use the table() function to view the clustering result. As in the previous question, how would you label each of these 5 clusters? 
```{r, fig.width=10, fig.height=8}
set.seed(20)
# Hierarchical clustering with Ward's linkage
hc1 <- hclust(dis, method = 'ward.D')

# Plotting
plot(hc1)
rect.hclust(hc1, 5)

# Labeling 5 clusters
hc_5 <- cutree(hc1, 5)
comp1 <- data.frame(hc_5, diagnosis)
with(comp1, table(hc_5, diagnosis))
```
I would label Clusters 1 and 2 as malignant, and Clusters 3, 4, and 5 as benign.

## K-Means Clustering (15 points)

18. Perform k-means clustering on this dataset using the kmeans() function with K=2. Then use the table() function and the diagnosis label to compare the diagnostic composition (benign vs. malignant) of each of the 2 clusters (hint: the cluster information from k-means is stored in the $cluster attribute of the k-means result.)
```{r}
set.seed(20)
# Perform Kmeans clustering and create table of amount of diagnoses per cluster
km <- kmeans(cancer[,-1], 2, nstart = 20)
comp2 <- data.frame(km$cluster, diagnosis)
with(comp2, table(km$cluster, diagnosis))
```
Cluster 1 I would label as benign and Cluster 2 as malignant.

19. Visualize the clusters using the fviz_cluster() function from the factoextra package.
```{r}
fviz_cluster(km, data = cancer[,-1])
```


20. What is the benefit of hierarchical clustering over k-means based on the example problem we have just explored?
The benefit is that you do not have to pre-specify how many clusters you want as you do with K-means. Choosing the correct number of clusters can be difficult when using K-means. With Hierarchical, you take a bottom-up approach, and begin with each data point as its own cluster and you merge clusters together. You can then choose how many clusters you'd like after viewing the dendrogram.
